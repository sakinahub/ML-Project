# -*- coding: utf-8 -*-
"""Miniproject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LD-pnfJ1jdjbsxztaxQUsJlhJFlikJVo

# **BREAST CANCER PREDICTION**
To predict whether the cancer is benign or malignant

*   Benign Tumour
  *   Non-cancerous growths
  *   Usually slow-growing and well-defined
  *   Do not invade nearby tissues or spread to other parts of the body
  *   Generally considered less serious and often removable with surgery
  *   Rarely life-threatening



*   Malignant Tumour
  *   Cancerous growths
  *   Can grow rapidly and aggressively
  *   Invade surrounding tissues and organs
  *   Can spread (metastasize) to distant parts of the body via bloodstream or lymphatic system
  *   Require prompt treatment such as surgery, chemotherapy, or radiation
  *   Potentially life-threatening if untreated

**Basic Functionalities**
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import warnings
warnings.filterwarnings("ignore")

data = pd.read_csv('data.csv')

data.head()

data.shape

data.info()

data.describe()

data.isnull().sum()

data['diagnosis'].value_counts()

data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})

data

"""# **LINEAR REGRESSION**"""

# Fit the linear regression model
features = ['radius_mean', 'texture_mean', 'area_mean', 'smoothness_mean', 'compactness_mean']
X = data[features]
y = data['diagnosis']  # Assume diagnosis is already encoded as 0 (benign), 1 (malignant)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred)
plt.plot([0, 1], [0, 1], 'r--')  # Ideal line (pred = true)

plt.xlabel("Actual Diagnosis (0 = Benign, 1 = Malignant)")
plt.ylabel("Predicted Value (Linear Output)")
plt.title("Linear Regression: Predicted vs Actual Diagnosis")
plt.grid(True)
plt.show()

"""# **LOGISTIC REGRESSION**"""

features = ['radius_mean','texture_mean','area_mean','smoothness_mean','compactness_mean']
X = data[features]
y = data['diagnosis']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

model = LogisticRegression()
model.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
y_pred = model.predict(X_test)

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Create the display with a custom colormap (e.g., 'Blues', 'Purples', 'YlGnBu', 'BuPu')
disp = ConfusionMatrixDisplay(confusion_matrix=cm)

# Plot with styling
fig, ax = plt.subplots(figsize=(6, 5))
disp.plot(cmap='YlGnBu', ax=ax, colorbar=True)
# Title and formatting
plt.title("Confusion Matrix - Breast Cancer Prediction", fontsize=14)
plt.xlabel("Predicted Label", fontsize=12)
plt.ylabel("True Label", fontsize=12)
plt.grid(False)
plt.show()

model.score(X_test, y_test)

plt.figure(figsize=(6, 4))
sns.countplot(x='diagnosis', data=data)
plt.title('Distribution of Diagnosis (Malignant vs. Benign)')
plt.xlabel('Diagnosis (0: Benign, 1: Malignant)')
plt.ylabel('Count')
plt.xticks(ticks=[0, 1], labels=['Benign (0)', 'Malignant (1)'])
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Convert diagnosis to string labels for better hue legends
data['diagnosis_label'] = data['diagnosis'].map({0: 'Benign', 1: 'Malignant'})

# Pairplot with hue
sns.pairplot(data, hue='diagnosis_label', vars=[ 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean'], palette='Set1')
plt.legend(title='Diagnosis', loc='upper right', labels=['Benign (0)', 'Malignant (1)'])
plt.suptitle('Pairplot of Selected Features by Diagnosis', y=1.02)
plt.tight_layout()
plt.show()

features = ['radius_mean', 'texture_mean', 'area_mean', 'concavity_mean']

for feature in features:
    plt.figure(figsize=(7, 4))
    sns.boxplot(x='diagnosis_label', y=feature, data=data, palette='Set3')
    plt.title(f'Boxplot of {feature} by Diagnosis')
    plt.xlabel('Diagnosis')
    plt.ylabel(feature)
    plt.tight_layout()
    plt.show()

report = classification_report(y_test, y_pred, target_names=['Benign', 'Malignant'])
print("Classification Report:\n")
print(report)

# Define the feature to use for plotting the logistic regression curve
feature_log = 'radius_mean'

# Use the existing logistic regression model
log_model = model

# Select the feature for training and testing the log model
X_log = data[[feature_log]]
y_log = data['diagnosis']

# Split the data for the log model
X_log_train, X_log_test, y_log_train, y_log_test = train_test_split(X_log, y_log, test_size=0.25, random_state=42)

from sklearn.linear_model import LogisticRegression

# Train a model on only radius_mean for visualization
log_model_1d = LogisticRegression()
log_model_1d.fit(X_train[['radius_mean']], y_train)

# Generate predictions
radius_range = np.linspace(X_test['radius_mean'].min(), X_test['radius_mean'].max(), 300)
radius_range_reshaped = radius_range.reshape(-1, 1)
probs_plot = log_model_1d.predict_proba(radius_range_reshaped)[:, 1]

# Plot
plt.figure(figsize=(8, 5))
plt.scatter(X_test['radius_mean'], y_test, c=y_test, cmap='bwr', edgecolors='white', label='Data points')
plt.plot(radius_range, probs_plot, color='blue', linewidth=2, label='Logistic Curve')
plt.xlabel('Radius Mean')
plt.ylabel('Probability of Malignant (1)')
plt.title('Logistic Regression on Radius Mean Only')
plt.legend()
plt.grid(True)
plt.show()